{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NiHU8V0smcmW"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input,LSTM,Dense,Embedding,Attention,Concatenate\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np"]},{"cell_type":"code","source":["text_pairs = [\n","    (\"I love Python\", \"J'adore Python\"),\n","    (\"Hello world\", \"Bonjour le monde\"),\n","    (\"Good morning\", \"Bonjour\"),\n","    (\"How are you\", \"Comment allez-vous\"),\n","    (\"See you later\", \"A plus tard\")\n","]\n","\n","input_texts = [pair[0] for pair in text_pairs]\n","target_texts = ['\\t' + pair[1] + '\\n' for pair in text_pairs]\n","\n","input_characters = sorted(list(set(''.join(input_texts))))\n","target_characters = sorted(list(set(''.join(target_texts))))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","\n","\n","input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n","target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n","reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n","\n","\n","encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float32')\n","decoder_input_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","decoder_target_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","\n","\n","for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","    for t, char in enumerate(input_text):\n","        encoder_input_data[i, t, input_token_index[char]] = 1.0\n","    for t, char in enumerate(target_text):\n","        decoder_input_data[i, t, target_token_index[char]] = 1.0\n","        if t > 0:\n","            decoder_target_data[i, t-1, target_token_index[char]] = 1.0\n","\n","embedding_size = 256\n","lstm_units = 256\n","\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder_lstm = LSTM(lstm_units, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n","encoder_states = [state_h, state_c]\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit([encoder_input_data, decoder_input_data],\n","          decoder_target_data,\n","          batch_size=64,\n","          epochs=100,\n","          validation_split=0.2)\n","encoder_model = Model(encoder_inputs, encoder_states)\n","decoder_state_input_h = Input(shape=(lstm_units,))\n","decoder_state_input_c = Input(shape=(lstm_units,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)\n","\n","def translate(input_sentence):\n","\n","    input_seq = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n","    for t, char in enumerate(input_sentence):\n","        if char in input_token_index:\n","            input_seq[0, t, input_token_index[char]] = 1.0\n","\n","    states_value = encoder_model.predict(input_seq)\n","\n","\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    target_seq[0, 0, target_token_index['\\t']] = 1.0\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n","            stop_condition = True\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.0\n","        states_value = [h, c]\n","\n","    return decoded_sentence.strip()\n","test_sentences = [\"Hello world\", \"Good morning\", \"I love Python\"]\n","print(\"\\nTranslations:\")\n","for sentence in test_sentences:\n","    translation = translate(sentence)\n","    print(f\"Input: {sentence}\")\n","    print(f\"Output: {translation}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MGeijgqqqzNH","outputId":"16e96fc9-3ba2-4ac5-a90f-ce0eac0a3943"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0375 - loss: 2.4361 - val_accuracy: 0.0000e+00 - val_loss: 1.9767\n","Epoch 2/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777ms/step - accuracy: 0.1250 - loss: 2.4166 - val_accuracy: 0.0000e+00 - val_loss: 1.9755\n","Epoch 3/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.1250 - loss: 2.4005 - val_accuracy: 0.0000e+00 - val_loss: 1.9744\n","Epoch 4/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1125 - loss: 2.3847 - val_accuracy: 0.0000e+00 - val_loss: 1.9731\n","Epoch 5/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.1125 - loss: 2.3672 - val_accuracy: 0.0000e+00 - val_loss: 1.9714\n","Epoch 6/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.1125 - loss: 2.3455 - val_accuracy: 0.0000e+00 - val_loss: 1.9689\n","Epoch 7/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.1125 - loss: 2.3150 - val_accuracy: 0.0000e+00 - val_loss: 1.9653\n","Epoch 8/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.1125 - loss: 2.2653 - val_accuracy: 0.0000e+00 - val_loss: 1.9660\n","Epoch 9/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.1125 - loss: 2.1949 - val_accuracy: 0.0500 - val_loss: 1.9519\n","Epoch 10/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.1250 - loss: 2.1743 - val_accuracy: 0.0000e+00 - val_loss: 2.0243\n","Epoch 11/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.1125 - loss: 2.1251 - val_accuracy: 0.0500 - val_loss: 1.9365\n","Epoch 12/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.1500 - loss: 2.1481 - val_accuracy: 0.0000e+00 - val_loss: 2.0178\n","Epoch 13/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.1250 - loss: 2.0448 - val_accuracy: 0.0500 - val_loss: 2.0310\n","Epoch 14/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.1250 - loss: 2.0170 - val_accuracy: 0.0000e+00 - val_loss: 2.1002\n","Epoch 15/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.1375 - loss: 1.9882 - val_accuracy: 0.0500 - val_loss: 2.0627\n","Epoch 16/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.1250 - loss: 1.9579 - val_accuracy: 0.0000e+00 - val_loss: 2.1969\n","Epoch 17/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.1125 - loss: 1.9316 - val_accuracy: 0.0500 - val_loss: 2.0953\n","Epoch 18/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.1250 - loss: 1.9386 - val_accuracy: 0.0000e+00 - val_loss: 2.2536\n","Epoch 19/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.1750 - loss: 1.8779 - val_accuracy: 0.0500 - val_loss: 2.1962\n","Epoch 20/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.1375 - loss: 1.9550 - val_accuracy: 0.0000e+00 - val_loss: 2.2310\n","Epoch 21/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.1875 - loss: 1.8481 - val_accuracy: 0.1000 - val_loss: 2.2823\n","Epoch 22/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.1750 - loss: 1.8139 - val_accuracy: 0.0000e+00 - val_loss: 2.3108\n","Epoch 23/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.2375 - loss: 1.7730 - val_accuracy: 0.0500 - val_loss: 2.3179\n","Epoch 24/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.1125 - loss: 1.8556 - val_accuracy: 0.0000e+00 - val_loss: 2.4101\n","Epoch 25/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1875 - loss: 1.7932 - val_accuracy: 0.0500 - val_loss: 2.2852\n","Epoch 26/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.1375 - loss: 1.9283 - val_accuracy: 0.0500 - val_loss: 2.3273\n","Epoch 27/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.2250 - loss: 1.7845 - val_accuracy: 0.0000e+00 - val_loss: 2.4096\n","Epoch 28/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.2375 - loss: 1.7263 - val_accuracy: 0.1000 - val_loss: 2.3634\n","Epoch 29/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1875 - loss: 1.7384 - val_accuracy: 0.0000e+00 - val_loss: 2.5239\n","Epoch 30/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.2000 - loss: 1.7204 - val_accuracy: 0.0500 - val_loss: 2.3813\n","Epoch 31/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.1500 - loss: 1.8678 - val_accuracy: 0.0500 - val_loss: 2.4205\n","Epoch 32/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.2125 - loss: 1.7077 - val_accuracy: 0.0500 - val_loss: 2.4845\n","Epoch 33/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.2250 - loss: 1.6703 - val_accuracy: 0.1000 - val_loss: 2.4555\n","Epoch 34/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.2125 - loss: 1.6626 - val_accuracy: 0.0000e+00 - val_loss: 2.6103\n","Epoch 35/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.2000 - loss: 1.6564 - val_accuracy: 0.1000 - val_loss: 2.3978\n","Epoch 36/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1375 - loss: 1.8381 - val_accuracy: 0.0000e+00 - val_loss: 2.4890\n","Epoch 37/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.2500 - loss: 1.6411 - val_accuracy: 0.0500 - val_loss: 2.5664\n","Epoch 38/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.2375 - loss: 1.6130 - val_accuracy: 0.0000e+00 - val_loss: 2.5479\n","Epoch 39/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.2375 - loss: 1.6029 - val_accuracy: 0.0000e+00 - val_loss: 2.6500\n","Epoch 40/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.2625 - loss: 1.5807 - val_accuracy: 0.1000 - val_loss: 2.5030\n","Epoch 41/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - accuracy: 0.1750 - loss: 1.6918 - val_accuracy: 0.0000e+00 - val_loss: 2.7820\n","Epoch 42/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.1625 - loss: 1.7253 - val_accuracy: 0.0500 - val_loss: 2.5345\n","Epoch 43/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.1375 - loss: 1.8885 - val_accuracy: 0.1000 - val_loss: 2.5013\n","Epoch 44/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.1875 - loss: 1.7187 - val_accuracy: 0.0000e+00 - val_loss: 2.6300\n","Epoch 45/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.2500 - loss: 1.6333 - val_accuracy: 0.0500 - val_loss: 2.5251\n","Epoch 46/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.2500 - loss: 1.6204 - val_accuracy: 0.0000e+00 - val_loss: 2.7138\n","Epoch 47/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.2625 - loss: 1.5927 - val_accuracy: 0.1000 - val_loss: 2.5095\n","Epoch 48/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.2375 - loss: 1.6223 - val_accuracy: 0.0000e+00 - val_loss: 2.7791\n","Epoch 49/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.2250 - loss: 1.5755 - val_accuracy: 0.1000 - val_loss: 2.5187\n","Epoch 50/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.1875 - loss: 1.6521 - val_accuracy: 0.0000e+00 - val_loss: 2.7401\n","Epoch 51/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.2125 - loss: 1.5556 - val_accuracy: 0.1000 - val_loss: 2.6095\n","Epoch 52/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1875 - loss: 1.6569 - val_accuracy: 0.0000e+00 - val_loss: 2.7205\n","Epoch 53/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.3500 - loss: 1.5545 - val_accuracy: 0.1000 - val_loss: 2.6228\n","Epoch 54/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2000 - loss: 1.6136 - val_accuracy: 0.0000e+00 - val_loss: 2.7615\n","Epoch 55/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.2750 - loss: 1.5287 - val_accuracy: 0.1000 - val_loss: 2.6132\n","Epoch 56/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.2125 - loss: 1.6053 - val_accuracy: 0.0000e+00 - val_loss: 2.7853\n","Epoch 57/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.2875 - loss: 1.5063 - val_accuracy: 0.1000 - val_loss: 2.5697\n","Epoch 58/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.2250 - loss: 1.5891 - val_accuracy: 0.0000e+00 - val_loss: 2.8777\n","Epoch 59/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.2125 - loss: 1.5049 - val_accuracy: 0.1000 - val_loss: 2.5279\n","Epoch 60/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.2625 - loss: 1.6097 - val_accuracy: 0.0000e+00 - val_loss: 2.8186\n","Epoch 61/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.2500 - loss: 1.4903 - val_accuracy: 0.0500 - val_loss: 2.6118\n","Epoch 62/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.2500 - loss: 1.5609 - val_accuracy: 0.0000e+00 - val_loss: 2.8088\n","Epoch 63/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.2500 - loss: 1.6056 - val_accuracy: 0.0000e+00 - val_loss: 2.7905\n","Epoch 64/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.3500 - loss: 1.4771 - val_accuracy: 0.1000 - val_loss: 2.6539\n","Epoch 65/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.2375 - loss: 1.5316 - val_accuracy: 0.0000e+00 - val_loss: 2.8541\n","Epoch 66/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.3125 - loss: 1.4661 - val_accuracy: 0.1000 - val_loss: 2.6035\n","Epoch 67/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.2000 - loss: 1.5756 - val_accuracy: 0.0500 - val_loss: 2.8181\n","Epoch 68/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.3375 - loss: 1.4199 - val_accuracy: 0.0500 - val_loss: 2.7242\n","Epoch 69/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.2875 - loss: 1.4927 - val_accuracy: 0.0000e+00 - val_loss: 2.8373\n","Epoch 70/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.3250 - loss: 1.4322 - val_accuracy: 0.1500 - val_loss: 2.8192\n","Epoch 71/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.2375 - loss: 1.5748 - val_accuracy: 0.0000e+00 - val_loss: 2.8154\n","Epoch 72/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.3500 - loss: 1.3901 - val_accuracy: 0.1000 - val_loss: 2.6837\n","Epoch 73/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.4000 - loss: 1.4022 - val_accuracy: 0.0000e+00 - val_loss: 3.0041\n","Epoch 74/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.2750 - loss: 1.4205 - val_accuracy: 0.0000e+00 - val_loss: 2.5645\n","Epoch 75/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.2000 - loss: 1.6643 - val_accuracy: 0.0500 - val_loss: 2.7692\n","Epoch 76/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.3125 - loss: 1.4843 - val_accuracy: 0.0000e+00 - val_loss: 2.9939\n","Epoch 77/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.2625 - loss: 1.4120 - val_accuracy: 0.0500 - val_loss: 2.7201\n","Epoch 78/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.3000 - loss: 1.4475 - val_accuracy: 0.0000e+00 - val_loss: 2.8510\n","Epoch 79/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.3500 - loss: 1.3818 - val_accuracy: 0.0500 - val_loss: 2.8160\n","Epoch 80/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.3750 - loss: 1.3262 - val_accuracy: 0.0000e+00 - val_loss: 2.8760\n","Epoch 81/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.3375 - loss: 1.4532 - val_accuracy: 0.0000e+00 - val_loss: 2.8793\n","Epoch 82/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3750 - loss: 1.3306 - val_accuracy: 0.0500 - val_loss: 2.7801\n","Epoch 83/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.3750 - loss: 1.3879 - val_accuracy: 0.0000e+00 - val_loss: 2.9983\n","Epoch 84/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.3375 - loss: 1.3196 - val_accuracy: 0.1500 - val_loss: 2.7767\n","Epoch 85/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.2625 - loss: 1.5093 - val_accuracy: 0.0000e+00 - val_loss: 2.8481\n","Epoch 86/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.3875 - loss: 1.2785 - val_accuracy: 0.0000e+00 - val_loss: 2.8934\n","Epoch 87/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.3875 - loss: 1.2577 - val_accuracy: 0.0000e+00 - val_loss: 2.9910\n","Epoch 88/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.3500 - loss: 1.2802 - val_accuracy: 0.0000e+00 - val_loss: 3.0364\n","Epoch 89/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.3000 - loss: 1.5364 - val_accuracy: 0.1500 - val_loss: 2.9526\n","Epoch 90/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.2500 - loss: 1.5610 - val_accuracy: 0.0000e+00 - val_loss: 3.0765\n","Epoch 91/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.3000 - loss: 1.4040 - val_accuracy: 0.0500 - val_loss: 2.8772\n","Epoch 92/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.2875 - loss: 1.4166 - val_accuracy: 0.0000e+00 - val_loss: 3.0112\n","Epoch 93/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.3250 - loss: 1.3794 - val_accuracy: 0.0500 - val_loss: 2.9179\n","Epoch 94/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.4000 - loss: 1.2778 - val_accuracy: 0.0000e+00 - val_loss: 2.9020\n","Epoch 95/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.3625 - loss: 1.2956 - val_accuracy: 0.0000e+00 - val_loss: 3.0154\n","Epoch 96/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.3875 - loss: 1.2379 - val_accuracy: 0.1000 - val_loss: 2.8405\n","Epoch 97/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.3375 - loss: 1.3810 - val_accuracy: 0.0000e+00 - val_loss: 3.0234\n","Epoch 98/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.4000 - loss: 1.2098 - val_accuracy: 0.0500 - val_loss: 2.8932\n","Epoch 99/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.3375 - loss: 1.3002 - val_accuracy: 0.0000e+00 - val_loss: 3.0549\n","Epoch 100/100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.4125 - loss: 1.1837 - val_accuracy: 0.0500 - val_loss: 2.9203\n","\n","Translations:\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","Input: Hello world\n","Output: Bonjour\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","Input: Good morning\n","Output: Bonjour\n","\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","Input: I love Python\n","Output: J'adorr  oo\n","\n"]}]}]}